---
title: "w203_Lab3_group5_draft1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Part1: Looking at the data

This part is to look at the dataset in general to grow our understand of the data:

```{r }
library(car)
data <- read.csv(file="crime_v2.csv", header=TRUE, sep=",",na.strings=c("`","","NA"))
objects(data)

```

```{r}
summary(data)
```

```{r}
tail(data,11)
```

```{r}
hist(data$prbconv, breaks=20, main="prbconv", xlab="prbconv")
```

Some of the things we see in the dataset:
1. 6 NA
2. take out year column
3. "prbarr" max > 1
4. "prbconv" strange characters and blank spaces; also the probability is bigger than 1
5. taxpc, what is the unit, what does it mean? Outlier at 119. Is the unit %?
6. pctmin80 data is too old
7. 15-23: different industry avg. wages
8. 24 mix: ratio of face-to-face crime
9. percentage young male (what is the age:15-24)

```{r }
hist(data$prbconv, breaks=20, main="prbconv", xlab="prbconv")
```
With the import method modified, we are able to address the missing values and the special character error in the $prbconv$ data column

### Data Cleaning
1. remove NA
```{r }
data <- na.omit(data)
summary(data)
```
2. take out year column as it does not mean anything in our analysis
```{r }
data_clean <- subset(data,select=-c(year))
objects(data_clean)
```
3. "prbarr" max > 1
```{r }
data_clean <- subset(data_clean,data_clean$prbarr <1)
hist(data_clean$prbarr, breaks=20,  main="prbarr", xlab="prbarr")
```
4. "prbconv" strange characters and blank spaces; also the probability is bigger than 1 <br>
__blank space and strange characters are taken care of in data import__
```{r }
data_clean <- subset(data_clean,data_clean$prbconv <1)
hist(data_clean$prbconv, breaks=20, main="prbconv", xlab="prbconv")
```
5. taxpc: There seems to be some anomaly that is very far apart from other data points, but we have no evidence to say whether the data has anomaly or not. It could be an error or it could just be that the county has high tax per capita
```{r }
hist(data_clean$taxpc, breaks=20, main="taxpc", xlab="taxpc")
```
6. over-paid service industry: we found that the maximum value of the avg. weekly wage of service industry is above 2000, which is way more than the other industries. Based on the background knowledge, we don't believe there should be significant difference between the service industry and other industries in terms of compensation difference, and the data point above 2000 should be an error in the data, and we decided to remove them

```{r }
data_clean <- subset(data_clean, data_clean$wser<1000)
summary(data_clean$wser)
```

### EDA
1. As the first part of the data analysis, we are taking a look at the distributions of the dependent variable:

```{r }
hist(data_clean$crmrte,breaks=50, main="crmrte", xlab="crmrte")
```
```{r }
hist(log(data_clean$crmrte),breaks=50, main="Log transform of crmrte", xlab="Log of crmrte")
```
2. As the second part of the EDA, we take an initial look at the simple correlation between each variable inside the dataframe to help us understand the general correlations betwen each varible and the dependent variable to help identify the explanatory variables of interest
```{r }
# correlation plot
library(corrplot)
corrplot(cor(data_clean[,sapply(data_clean,is.numeric)]),is.corr=T, method = "circle", type='upper',main = "Correlation Plot", tl.cex=0.8)
```

### Research Question
After the initial data cleaning and data analysis, we have defined our research question to be: how to reduce crime rate within North Carolina, and especially how to reduce crime rate by increasing the arrest probability for non face-to-face crime

The question is asked to help the political campaign to propose effective strategies to reduce crime rate, especially in the area that might have been neglected before. From the simple correlation plot, we found that variable $mix$ has strong positive correlation with $prbarr$. It can make sense because face-to-face crimes are more severe and usually have more police concentration and resources that lead to higher probability of arrest. However, it might not be very easy for non face-to-face crime, which is still the majority of crimes that happened, but actually seem to have pretty low arrest rate. This conclusion can be obtained by the fact that crime rate ($crmrte$) is negatively correlated with probability of arrest($prbarr$) while percentage of face-to-face crime ($mix$) is positively correlated with probability of arrest ($prbarr$). Therefore, how to increase $prbarr$ for non face-to-face crime is really the strategy we need to focus our energy on.

### Fitting model 1
__model 1__: crmrte = $\beta_0 + \beta_1 * prbarr + \beta_2 * prbconv + \beta_3 * avgsen + \beta_4 * prbpris + u $ <br>

Based on the understanding of what each parameter stands for, we have chosen crmrte as the only dependent variable to use for our analysis. The variable is a direct indicator of average crime commited to North Carolina counties. To start with, we took a look at the distribution of the dataset.<br>

From the analysis of the EDA, the distribution of crmrte does not look particularly normal, but the log transformed crmrte looks much more normally distributed. To reduce the standard error in the model building process, we decided that in our model fitting, we are going to use the log transformed $crmrte$ as our dependent variable. <br>
That being said, we are creating another variable that indicates the log transformed $crmrte$
```{r }
data_clean$crmrte_log <- log(data_clean$crmrte)
hist(data_clean$crmrte_log, breaks=50, main="log transformation of 
crime rate per capita")
```
Looking at the other variables, and the simple correlation plot in initial EDA, we are proposing the explanatory variables that we believe contribute to crime rate: <br>

1. prbarr: the probability of arrest should be a direct contributing factor to crime rate. In other words, if people who have potential to commit a crime believe the chance of them getting arrested is small, then it might encourage them to commit a crime
2. prbconv: after getting arrested, getting suspects convicted are the only way to let them take the punishment they deserve.
3. prbpris
4. avgsen: both probability of prison sentence reflect the severity of the punishment, which should directly impact the crime rate

With the above being proposed, we decided to take a look at the distribution of each explanatory variable:

```{r }
# prbarr
hist(data_clean$prbarr,breaks=50,main="prbarr", xlab="prbarr")
```
```{r }
#prbconv
hist(data_clean$prbconv,breaks=50,main="prbconv", xlab="prbconv")
```
```{r }
#prbpris
hist(data_clean$prbpris,breaks=50,main="prbpris", xlab="prbpris")
```
```{r }
#avgsen
hist(data_clean$avgsen,breaks=50,main="avgsen", xlab="avgsen")

```
The above histograms of each explanatory variable all seem rather normally distributed, with some anomalies implied in $prbarr$ and $avgsen$. However, we don't think there is enough evidence to make a decision on whether the data is anomaly or not, and we will use the data for model building.

_Fitting model 1__:<br>
With the above explained reason, we are building the model1 with the explanatory variable of key interest as below:<br>
crmrte_log = $\beta_0 + \beta_1 * prbarr + \beta_2 * prbconv + \beta_3 * avgsen + \beta_4 * prbpris + u $ 

```{r }
model1 <- lm(crmrte_log ~ prbarr + prbconv + avgsen + prbpris, data=data_clean)
model1
```

_Fitting model 2__:<br>
With the second model, we are building it on top of model 1 but adding more variables that can have influence on the dependent variable crmte. For the purpose of building the model, we added two additional variables: nonFtF and polpcMult. nonFtf is the transformation of mix. It represent the non face to face offense. And polpcMult is the transformation of polpc. We need to multiply polpc by 100 becuase the numbers are too small. Without the multiplication, polpc skewed the model significantly. After the data transformation, the model is as below: <br>
crmrte_log = $\beta_0 + \beta_1 * prbarr + \beta_2 * prbconv + \beta_3 * avgsen + \beta_4 * prbpris + \beta_5 * nonFtf + \beta_6 * taxpc + \beta_7 * urban + \beta_8 * pctymle + \beta_9 * popcMutl + u $ 

```{r }
data_clean$nonFtf <- (1- data_clean$mix)
data_clean$polpcMult <- data_clean$polpc * 100
model2 <- lm(crmrte_log ~ prbarr + prbconv + avgsen + prbpris + nonFtf + taxpc + urban + pctymle + polpcMult, data=data_clean)
model2
```










